# About
We are the HumanAIGC Team at Tongyi, Alibaba. We focus on the understanding and generation of human-centric content.

# Projects 
- **MirrorMe**: Towards Realtime and High Fidelity Audio-Driven Halfbody Animation. [Paper](https://arxiv.org/abs/2506.22065)
- **SwapAnyHead**: Controllable and Expressive One-Shot Video Head Swapping. [Project](https://humanaigc.github.io/SwapAnyHead/), [Paper](https://arxiv.org/abs/2506.16852)
- **FaceTimelineControl**: Exploring Timeline Control for Facial Motion Generation. [Project](https://humanaigc.github.io/facial-motion-timeline-control/), [Paper](https://arxiv.org/abs/2505.20861)
- **MotionRAG-Diff**: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation. [Project](https://humanaigc.github.io/MotionRAG-Diff/), [Paper](https://arxiv.org/abs/2506.02661)
- **OmniTalker**: Real-Time Text-Driven Talking Head Generation with In-Context Audio-Visual Style Replication. [Project](https://humanaigc.github.io/omnitalker/), [Paper](https://arxiv.org/abs/2504.02433v1), [Demo](https://huggingface.co/spaces/Mrwrichard/OmniTalker)
- **ChatAnyone**: Stylized Real-time Portrait Video Generation with Hierarchical Motion Diffusion Model. [Project](https://humanaigc.github.io/chat-anyone/), [Paper](https://arxiv.org/abs/2503.21144)
- **LiteAvatar**: a audio2face model for realtime 2D chat avatar. [Code](https://github.com/HumanAIGC/lite-avatar)
- **Animate Anyone 2**: High-Fidelity Character Image Animation with Environment Affordance. [Project](https://humanaigc.github.io/animate-anyone-2/), [Paper](https://arxiv.org/pdf/2502.06145)
- **EMO2**: End-Effector Guided Audio-Driven Avatar Video Generation. [Project](https://humanaigc.github.io/emote-portrait-alive-2/), [Paper](https://arxiv.org/abs/2501.10687)
- **EMO**: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions. [Project](https://humanaigc.github.io/emote-portrait-alive/), [Paper](https://arxiv.org/abs/2402.17485)
- **Outfit Anyone**: Ultra-high quality virtual try-on for Any Clothing and Any Person. [Project](https://humanaigc.github.io/outfit-anyone/), [Paper](https://arxiv.org/pdf/2407.16224), [Demo](https://humanaigc.github.io/outfit-anyone/)
- **Animate Anyone**: Consistent and Controllable Image-to-Video Synthesis for Character Animation. [Project](https://humanaigc.github.io/animate-anyone/), [Paper](https://arxiv.org/pdf/2311.17117)
- **VividTalk**: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior. [Project](https://humanaigc.github.io/vivid-talk/), [Paper](https://arxiv.org/pdf/2312.01841)
- **DanceMeld**: Unraveling Dance Phrases with Hierarchical Latent Codes for Music-to-Dance Synthesis. [Paper](https://arxiv.org/abs/2401.10242)
- **Cloth2Tex**: A Customized Cloth Texture Generation Pipeline for 3D Virtual Try-On. [Project](https://tomguluson92.github.io/projects/cloth2tex/), [Paper](https://arxiv.org/abs/2308.04288), [Code](https://github.com/HumanAIGC/Cloth2Tex)
